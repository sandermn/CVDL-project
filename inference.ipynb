{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "according-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from torch import nn\n",
    "\n",
    "from DatasetLoader import DatasetLoader\n",
    "from Unet2D import Unet2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "silver-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dl, acc_fn):\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    running_acc = 0\n",
    "    for x, y in test_dl:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "            acc = acc_fn(outputs, y)\n",
    "\n",
    "        running_acc += acc * test_dl.batch_size\n",
    "    return running_acc\n",
    "\n",
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.cuda()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "actual-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    params_path = \"models/model_epoch_2.pth\"\n",
    "    bs = 12\n",
    "    # load the test data\n",
    "    # Current paths are incorrect\n",
    "    base_path = Path('/work/datasets/medical_project/CAMUS_resized')\n",
    "    data = DatasetLoader(base_path / 'train_gray',\n",
    "                         base_path / 'train_gt')\n",
    "    print(len(data))\n",
    "\n",
    "    # split the training dataset and initialize the data loaders\n",
    "    _, _, test_dataset = torch.utils.data.random_split(\n",
    "        data,\n",
    "        (300, 100, 50),\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "\n",
    "    # split the training dataset and initialize the data loaders\n",
    "    test_data = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "    xb, yb = next(iter(test_data))\n",
    "    print(xb.shape, yb.shape)\n",
    "\n",
    "    # build the Unet2D with one channel as input and 2 channels as output\n",
    "    unet = Unet2D(1, 2)\n",
    "    # Load best model params\n",
    "    unet.load_state_dict(torch.load(params_path))\n",
    "    # loss function and optimizer\n",
    "    # loss_fn = nn.CrossEntropyLoss()\n",
    "    # opt = torch.optim.Adam(unet.parameters())\n",
    "\n",
    "    # do some training\n",
    "    acc = test(unet, test_data, acc_metric)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "metallic-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "torch.Size([12, 1, 384, 384]) torch.Size([12, 384, 384])\n",
      "tensor(55.8430, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-cartridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
